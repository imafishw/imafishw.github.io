{"title":"RNN、LSTM原理以及代码实践1","uid":"3830d4aadcfd24ee5b2ca9f694f1c0fa","slug":"first-page","date":"2025-02-11T12:41:20.000Z","updated":"2025-02-28T09:04:15.321Z","comments":true,"path":"api/articles/first-page.json","keywords":null,"cover":null,"content":"<h3 id=\"一、文本预处理以及词元化-基础\"><a href=\"#一、文本预处理以及词元化-基础\" class=\"headerlink\" title=\"一、文本预处理以及词元化(基础)\"></a>一、文本预处理以及词元化(基础)</h3><h4 id=\"1、为什么要进行文本预处理以及词源化\"><a href=\"#1、为什么要进行文本预处理以及词源化\" class=\"headerlink\" title=\"1、为什么要进行文本预处理以及词源化\"></a>1、为什么要进行文本预处理以及词源化</h4><p><strong><font style=\"color:#DF2A3F;\">训练时用字符串直接进行训练是不好训练的，通常我们建立一个词表，例如基于词元级别(什么意思呢？其实就是拆分句子的过程以英语词为单位)于此同时,也有基于字符级的拆分来构建我们的词表 这里用的是李沐老师的d2l库中的数据</font></strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> collections</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#@save</span></span><br><span class=\"line\">d2l.DATA_HUB[<span class=\"string\">&#x27;time_machine&#x27;</span>] = (d2l.DATA_URL + <span class=\"string\">&#x27;timemachine.txt&#x27;</span>,</span><br><span class=\"line\">                                <span class=\"string\">&#x27;090b5e7e70c295757f55df93cb0a180b9691891a&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">read_time_machine</span>():  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;将时间机器数据集加载到文本行的列表中&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(d2l.download(<span class=\"string\">&#x27;time_machine&#x27;</span>), <span class=\"string\">&#x27;r&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        lines = f.readlines()</span><br><span class=\"line\">        <span class=\"comment\"># 十分暴力的预处理 一般标点符号还是保留的</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> [re.sub(<span class=\"string\">&#x27;[^A-Za-z]+&#x27;</span>, <span class=\"string\">&#x27; &#x27;</span>, line).strip().lower() <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines]</span><br><span class=\"line\"></span><br><span class=\"line\">lines = read_time_machine()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;# 文本总行数: <span class=\"subst\">&#123;<span class=\"built_in\">len</span>(lines)&#125;</span>&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(lines[<span class=\"number\">0</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(lines[<span class=\"number\">10</span>])</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p><strong># 文本总行数: 3221</strong></p>\n<p><strong>the time machine by h g wells</strong></p>\n<p><strong>twinkled and his usually pale face was flushed and animated the</strong></p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">tokenize</span>(<span class=\"params\">lines, token=<span class=\"string\">&#x27;word&#x27;</span></span>):  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;将文本行拆分为单词或字符词元&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> token == <span class=\"string\">&#x27;word&#x27;</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [line.split() <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines]</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> token == <span class=\"string\">&#x27;char&#x27;</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [<span class=\"built_in\">list</span>(line) <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines]</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;错误：未知词元类型：&#x27;</span> + token)</span><br><span class=\"line\"></span><br><span class=\"line\">tokens = tokenize(lines)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">11</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(tokens[i])</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&#x27;the&#x27;, &#x27;time&#x27;, &#x27;machine&#x27;, &#x27;by&#x27;, &#x27;h&#x27;, &#x27;g&#x27;, &#x27;wells&#x27;]</span><br><span class=\"line\">[]</span><br><span class=\"line\">[]</span><br><span class=\"line\">[]</span><br><span class=\"line\">[]</span><br><span class=\"line\">[&#x27;i&#x27;]</span><br><span class=\"line\">[]</span><br><span class=\"line\">[]</span><br><span class=\"line\">[&#x27;the&#x27;, &#x27;time&#x27;, &#x27;traveller&#x27;, &#x27;for&#x27;, &#x27;so&#x27;, &#x27;it&#x27;, &#x27;will&#x27;, &#x27;be&#x27;, &#x27;convenient&#x27;, &#x27;to&#x27;, &#x27;speak&#x27;, &#x27;of&#x27;, &#x27;him&#x27;]</span><br><span class=\"line\">[&#x27;was&#x27;, &#x27;expounding&#x27;, &#x27;a&#x27;, &#x27;recondite&#x27;, &#x27;matter&#x27;, &#x27;to&#x27;, &#x27;us&#x27;, &#x27;his&#x27;, &#x27;grey&#x27;, &#x27;eyes&#x27;, &#x27;shone&#x27;, &#x27;and&#x27;]</span><br><span class=\"line\">[&#x27;twinkled&#x27;, &#x27;and&#x27;, &#x27;his&#x27;, &#x27;usually&#x27;, &#x27;pale&#x27;, &#x27;face&#x27;, &#x27;was&#x27;, &#x27;flushed&#x27;, &#x27;and&#x27;, &#x27;animated&#x27;, &#x27;the&#x27;]</span><br></pre></td></tr></table></figure>\n\n\n<p><font style=\"color:rgba(0, 0, 0, 0.87);background-color:rgb(250, 250, 250);\">词元的类型是字符串，而模型需要的输入是数字，因此这种类型不方便模型使用。 现在，让我们构建一个字典，通常也叫做</font><em><font style=\"color:rgba(0, 0, 0, 0.87);background-color:rgb(250, 250, 250);\">词表</font></em><font style=\"color:rgba(0, 0, 0, 0.87);background-color:rgb(250, 250, 250);\">（vocabulary）， 用来将字符串类型的词元映射到从</font><font style=\"color:rgba(0, 0, 0, 0.87);background-color:rgb(250, 250, 250);\">0</font><font style=\"color:rgba(0, 0, 0, 0.87);background-color:rgb(250, 250, 250);\">开始的数字索引中。 我们先将训练集中的所有文档合并在一起，对它们的唯一词元进行统计， 得到的统计结果称之为</font><em><font style=\"color:rgba(0, 0, 0, 0.87);background-color:rgb(250, 250, 250);\">语料</font></em><font style=\"color:rgba(0, 0, 0, 0.87);background-color:rgb(250, 250, 250);\">（corpus）。 然后根据每个唯一词元的出现频率，为其分配一个数字索引。 很少出现的词元通常被移除，这可以降低复杂性。 另外，语料库中不存在或已删除的任何词元都将映射到一个特定的未知词元“<unk>”。 我们可以选择增加一个列表，用于保存那些被保留的词元， 例如：填充词元（“<pad>”）； 序列开始词元（“<bos>”）； 序列结束词元（“<eos>”）。</font></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> collections</span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Vocab</span>:</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, tokens=<span class=\"literal\">None</span>, min_freq=<span class=\"number\">0</span>, reserved_tokens=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> tokens <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            tokens = []</span><br><span class=\"line\">        <span class=\"keyword\">if</span> reserved_tokens <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            reserved_tokens = []</span><br><span class=\"line\">        counter = count_corpus(tokens)</span><br><span class=\"line\">        <span class=\"comment\"># 返回词出现的频率</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>._token_freqs = <span class=\"built_in\">sorted</span>(counter.items(), key=<span class=\"keyword\">lambda</span> x: x[<span class=\"number\">1</span>], reverse=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 未知词元的索引为0</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.idx_to_token = [<span class=\"string\">&#x27;&lt;unk&gt;&#x27;</span>] + reserved_tokens</span><br><span class=\"line\">        <span class=\"comment\"># [&#x27;&lt;unk&gt;&#x27;, &#x27;&lt;bos&gt;&#x27;, &#x27;&lt;eos&gt;&#x27;]。</span></span><br><span class=\"line\">        <span class=\"comment\"># 变成这样的</span></span><br><span class=\"line\">        <span class=\"comment\"># &#123;&#x27;&lt;unk&gt;&#x27;:0, &#x27;&lt;bos&gt;&#x27;:1, &#x27;&lt;eos&gt;&#x27;:2&#125;。</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.token_to_idx = &#123;token: idx</span><br><span class=\"line\">                             <span class=\"keyword\">for</span> idx, token <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(<span class=\"variable language_\">self</span>.idx_to_token)&#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> token, freq <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>._token_freqs:</span><br><span class=\"line\">            <span class=\"comment\"># min_freq是我们规定的出现的最低频率次数 少于这个次数的词 不配进入词表</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> freq &lt; min_freq:</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> token <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.token_to_idx:</span><br><span class=\"line\">                <span class=\"comment\"># 构建索引以及对应的词元是什么</span></span><br><span class=\"line\">                <span class=\"variable language_\">self</span>.idx_to_token.append(token)</span><br><span class=\"line\">                <span class=\"variable language_\">self</span>.token_to_idx[token] = <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.idx_to_token) - <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.idx_to_token)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, tokens</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(tokens, (<span class=\"built_in\">list</span>, <span class=\"built_in\">tuple</span>)):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.token_to_idx.get(tokens, <span class=\"variable language_\">self</span>.unk)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [<span class=\"variable language_\">self</span>.__getitem__(token) <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> tokens]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">to_tokens</span>(<span class=\"params\">self, indices</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(indices, (<span class=\"built_in\">list</span>, <span class=\"built_in\">tuple</span>)):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.idx_to_token[indices]</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [<span class=\"variable language_\">self</span>.idx_to_token[index] <span class=\"keyword\">for</span> index <span class=\"keyword\">in</span> indices]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @property</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">unk</span>(<span class=\"params\">self</span>):  <span class=\"comment\"># 未知词元的索引为0</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @property</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">token_freqs</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>._token_freqs</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">count_corpus</span>(<span class=\"params\">tokens</span>):  <span class=\"comment\"># @save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;统计词元的频率&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 这里的tokens是1D列表或2D列表</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(tokens) == <span class=\"number\">0</span> <span class=\"keyword\">or</span> <span class=\"built_in\">isinstance</span>(tokens[<span class=\"number\">0</span>], <span class=\"built_in\">list</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 将词元列表展平成一个列表</span></span><br><span class=\"line\">        tokens = [token <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> tokens <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> line]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> collections.Counter(tokens)</span><br><span class=\"line\">vocab = Vocab(tokens)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">list</span>(vocab.token_to_idx.items())[:<span class=\"number\">100</span>])</span><br></pre></td></tr></table></figure>\n\n<p>输出 按出现频率排序的一个列表</p>\n<blockquote>\n<p>[(‘<unk>‘, 0), (‘the’, 1), (‘i’, 2), (‘and’, 3), (‘of’, 4), (‘a’, 5), (‘to’, 6), (‘was’, 7), (‘in’, 8), (‘that’, 9), (‘my’, 10), (‘it’, 11), (‘had’, 12), (‘me’, 13), (‘as’, 14), (‘at’, 15), (‘for’, 16), (‘with’, 17), (‘but’, 18), (‘time’, 19), (‘were’, 20), (‘this’, 21), (‘you’, 22), (‘on’, 23), (‘then’, 24), (‘his’, 25), (‘there’, 26), (‘he’, 27), (‘have’, 28), (‘they’, 29), (‘from’, 30), (‘one’, 31), (‘all’, 32), (‘not’, 33), (‘into’, 34), (‘upon’, 35), (‘little’, 36), (‘so’, 37), (‘is’, 38), (‘came’, 39), (‘by’, 40), (‘some’, 41), (‘be’, 42), (‘no’, 43), (‘could’, 44), (‘their’, 45), (‘said’, 46), (‘saw’, 47), (‘down’, 48), (‘them’, 49), (‘machine’, 50), (‘which’, 51), (‘very’, 52), (‘or’, 53), (‘an’, 54), (‘we’, 55), (‘now’, 56), (‘what’, 57), (‘been’, 58), (‘these’, 59), (‘like’, 60), (‘her’, 61), (‘out’, 62), (‘seemed’, 63), (‘up’, 64), (‘man’, 65), (‘about’, 66), (‘s’, 67), (‘its’, 68), (‘thing’, 69), (‘again’, 70), (‘traveller’, 71), (‘would’, 72), (‘more’, 73), (‘white’, 74), (‘our’, 75), (‘thought’, 76), (‘felt’, 77), (‘when’, 78), (‘over’, 79), (‘weena’, 80), (‘still’, 81), (‘world’, 82), (‘myself’, 83), (‘even’, 84), (‘must’, 85), (‘through’, 86), (‘if’, 87), (‘hand’, 88), (‘went’, 89), (‘first’, 90), (‘are’, 91), (‘before’, 92), (‘last’, 93), (‘towards’, 94), (‘only’, 95), (‘people’, 96), (‘she’, 97), (‘morlocks’, 98), (‘see’, 99)]</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> [<span class=\"number\">0</span>, <span class=\"number\">10</span>]:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;文本:&#x27;</span>, tokens[i])</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;索引:&#x27;</span>, vocab[tokens[i]])</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_corpus_time_machine</span>(<span class=\"params\">max_tokens=-<span class=\"number\">1</span></span>):  <span class=\"comment\">#@save</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;返回时光机器数据集的词元索引列表和词表&quot;&quot;&quot;</span></span><br><span class=\"line\">    lines = read_time_machine()</span><br><span class=\"line\">    tokens = tokenize(lines, <span class=\"string\">&#x27;char&#x27;</span>)</span><br><span class=\"line\">    vocab = Vocab(tokens)</span><br><span class=\"line\">    <span class=\"comment\"># 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，</span></span><br><span class=\"line\">    <span class=\"comment\"># 所以将所有文本行展平到一个列表中</span></span><br><span class=\"line\">    corpus = [vocab[token] <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> tokens <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> line]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> max_tokens &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        corpus = corpus[:max_tokens]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> corpus, vocab</span><br><span class=\"line\"></span><br><span class=\"line\">corpus, vocab = load_corpus_time_machine()</span><br><span class=\"line\"><span class=\"built_in\">len</span>(corpus), <span class=\"built_in\">len</span>(vocab)</span><br></pre></td></tr></table></figure>\n\n\n\n","text":"一、文本预处理以及词元化(基础)1、为什么要进行文本预处理以及词源化训练时用字符串直接进行训练是不好训练的，通常我们建立一个词表，例如基于词元级别(什么意思呢？...","permalink":"/post/first-page","photos":[],"count_time":{"symbolsCount":"6.6k","symbolsTime":"6 mins."},"categories":[],"tags":[{"name":"DeepLearn","slug":"DeepLearn","count":1,"path":"api/tags/DeepLearn.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%B8%80%E3%80%81%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%E4%BB%A5%E5%8F%8A%E8%AF%8D%E5%85%83%E5%8C%96-%E5%9F%BA%E7%A1%80\"><span class=\"toc-text\">一、文本预处理以及词元化(基础)</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#1%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%E4%BB%A5%E5%8F%8A%E8%AF%8D%E6%BA%90%E5%8C%96\"><span class=\"toc-text\">1、为什么要进行文本预处理以及词源化</span></a></li></ol></li></ol>","author":{"name":"WillamNan","slug":"blog-author","avatar":"https://ts1.cn.mm.bing.net/th/id/R-C.b9e21ed4bb3b6f8f887596d0aa0bdfd0?rik=gGo8lzF1jNmrVA&riu=http%3a%2f%2fimg.wennermedia.com%2f920-width%2frs-136803-0921fbfa76c66953268f4bdeee9410ef7ef02536.jpg&ehk=rWIlAmxhRw462ZiSZjtOWbhj2Wc%2fUdlNdtfKHaQMHn0%3d&risl=&pid=ImgRaw&r=0","link":"/","description":"去往下一个山巅","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{},"next_post":{"title":"Hello World","uid":"b9663f58f18133b35bfe243f3e916a80","slug":"hello-world","date":"2025-02-11T12:38:59.673Z","updated":"2025-02-11T12:37:20.231Z","comments":true,"path":"api/articles/hello-world.json","keywords":null,"cover":null,"text":"Welcome to Hexo! This is your very first post. Check documentation for more info...","permalink":"/post/hello-world","photos":[],"count_time":{"symbolsCount":444,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"WillamNan","slug":"blog-author","avatar":"https://ts1.cn.mm.bing.net/th/id/R-C.b9e21ed4bb3b6f8f887596d0aa0bdfd0?rik=gGo8lzF1jNmrVA&riu=http%3a%2f%2fimg.wennermedia.com%2f920-width%2frs-136803-0921fbfa76c66953268f4bdeee9410ef7ef02536.jpg&ehk=rWIlAmxhRw462ZiSZjtOWbhj2Wc%2fUdlNdtfKHaQMHn0%3d&risl=&pid=ImgRaw&r=0","link":"/","description":"去往下一个山巅","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}